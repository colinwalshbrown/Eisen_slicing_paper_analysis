{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fasta_subseq_2 as fa\n",
    "import seq_plotmethods as sp\n",
    "import itertools as it\n",
    "import tables as tb\n",
    "import numpy as np\n",
    "import subprocess as subp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Data Processing\n",
    "-\n",
    "- Start w/ gzipped .fastq files\n",
    "- Generate scripts to map reads using bowtie2 \n",
    "- Generate scripts to build h5 tables from mapped reads\n",
    "    - **RESIST THE TEMPTATION TO RE-CODE ANY OF THESE THINGS**\n",
    "- Generate scripts to run macs2 (GrizzlyPeaks?) for peak calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Working directory; change if necessary\n",
    "current_dir = \"[FILL_ME_IN]\"\n",
    "genomes_dir = current_dir + \"genomes/\"\n",
    "reads_dir = current_dir + \"reads/\"\n",
    "data_out_dir = current_dir + \"data/\"\n",
    "figs_dir = current_dir + \"figs/\"\n",
    "scripts_dir = current_dir + \"scripts/\"\n",
    "mapping_dir = data_out_dir + \"mapping/\"\n",
    "peaks_dir = data_out_dir + \"peaks/\"\n",
    "h5_dir = data_out_dir + \"hf5/\"\n",
    "\n",
    "# Dict of files to analyze\n",
    "to_analyze = {'gtA':'Ant_Gt_ChIP.fastq.gz',\n",
    "              'inA':'Ant_Input.fastq.gz',\n",
    "              'gtC':'Combo_Gt_ChIP.fastq.gz',\n",
    "              'inC':'Combo_Input.fastq.gz',\n",
    "              'gtP':'Post_Gt_ChIP.fastq.gz',\n",
    "              'inP':'Post_Input.fastq.gz',\n",
    "              'gtW1':'Whole1_Gt_ChIP.fastq.gz',\n",
    "              'inW1':'Whole1_Input.fastq.gz',\n",
    "              'gtW2':'Whole2_Gt_ChIP.fastq.gz',\n",
    "              'inW2':'Whole2_Input.fastq.gz',\n",
    "              }\n",
    "\n",
    "# sample / input pairs\n",
    "# note that I'm just using concatenated inputs for all dmel samples since few reads\n",
    "smp_in = {'gtA':'inA',\n",
    "          'gtC':'inC',\n",
    "          'gtP':'inP',\n",
    "          'gtW1':'inW1',\n",
    "          'gtW2':'inW2',\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build shell script to run bowtie2\n",
    "bt2_genome_index = current_dir + \"genomes/dmel+dpse\"\n",
    "\n",
    "bowtie2_cmd = \"bowtie2 --end-to-end \\\n",
    "--un-gz %s \\\n",
    "--no-unal \\\n",
    "--mm \\\n",
    "--qc-filter \\\n",
    "-x %s -U %s -S %s 1> %s 2> %s\"\n",
    "\n",
    "run_bowtie_sh = open(scripts_dir + \"run_bowtie.sh\",\"w+\")\n",
    "header = \"\"\"#!/bin/bash\n",
    "\n",
    "#####################################\n",
    "#\n",
    "# bash script to run bowtie2 on .fastq files in ../reads dir\n",
    "#\n",
    "\"\"\"\n",
    "\n",
    "print >> run_bowtie_sh, header\n",
    "for (name,readfile) in to_analyze.items():\n",
    "    print >> run_bowtie_sh, \"echo \\\"Starting %s...\\\"\" % name\n",
    "    print >> run_bowtie_sh, bowtie2_cmd % (mapping_dir+name+\"_unaligned.fastq.gz\",\n",
    "                                           bt2_genome_index,\n",
    "                                           reads_dir+readfile,\n",
    "                                           mapping_dir+name+\"_aln.sam\",\n",
    "                                           mapping_dir+name+\"_stdout.txt\",\n",
    "                                           mapping_dir+name+\"_stderr.txt\")\n",
    "    print >> run_bowtie_sh, \"echo \\\"Done!\\\"\"\n",
    "run_bowtie_sh.close()\n",
    "subp.call(['chmod','a+x',scripts_dir + 'run_bowtie.sh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grep out dmel & dpse samfiles\n",
    "grep_dmdp_sh = open(scripts_dir + \"grep_dmdp.sh\",\"w+\")\n",
    "header = \"\"\"#!/bin/bash\n",
    "\n",
    "\n",
    "#####################################\n",
    "#\n",
    "# bash script to grep dmel & dpse called reads from bowtie2 sam file \n",
    "#\n",
    "\"\"\"\n",
    "print >> grep_dmdp_sh, header\n",
    "for name in to_analyze.keys():\n",
    "    samfile = mapping_dir+name+\"_aln.sam\"\n",
    "    print >> grep_dmdp_sh, \"echo '%s...'\" % (name,)\n",
    "    print >> grep_dmdp_sh, \"grep \\\"\\tdpse_\\\" %s | perl -pe 's/dpse_//g' | grep -v 'mitochondrion_genome' | grep -v 'Unknown' | gzip > %s\" % (samfile,mapping_dir+name+\"_dpse_aln.sam.gz\")\n",
    "    print >> grep_dmdp_sh, \"grep \\\"\\tdmel_\\\" %s | perl -pe 's/dmel_//g' | grep -v 'mitochondrion_genome' | gzip > %s\" % (samfile,mapping_dir+name+\"_dmel_aln.sam.gz\")\n",
    "    print >> grep_dmdp_sh, \"echo 'done!'\"\n",
    "grep_dmdp_sh.close()\n",
    "subp.call(['chmod','a+x',scripts_dir + 'grep_dmdp.sh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run ChIP normalization scripts\n",
    "chip_norm_sh = open(scripts_dir + \"chip_norm.sh\",\"w+\")\n",
    "header = \"\"\"#!/bin/bash\n",
    "\n",
    "\n",
    "#####################################\n",
    "#\n",
    "# run chip_tagcount_normalize.py to generate pytables .hf5's for all data \n",
    "#\n",
    "\"\"\"\n",
    "print >> chip_norm_sh, header\n",
    "for name in to_analyze.keys():\n",
    "    print >> chip_norm_sh, \"echo 'normalizing %s...'\" % (name,)\n",
    "    print >> chip_norm_sh, \"chip_tagcount_normalize.py -n %s -q 30 -e 300 -o -u -z %s %s 1> %s 2> %s\" % (name+\"_dmel\",genomes_dir+\"dmel.fa\",mapping_dir+name+\"_dmel_aln.sam.gz\",mapping_dir+name+\"_dmel_tagnorm.stdout.txt\",mapping_dir+name+\"_dmel_tagnorm.stderr.txt\")\n",
    "    print >> chip_norm_sh, \"chip_tagcount_normalize.py -n %s -q 30 -e 300 -o -u -z %s %s 1> %s 2> %s\" % (name+\"_dpse\",genomes_dir+\"dpse.fa\",mapping_dir+name+\"_dpse_aln.sam.gz\",mapping_dir+name+\"_dpse_tagnorm.stdout.txt\",mapping_dir+name+\"_dpse_tagnorm.stderr.txt\")\n",
    "    print >> chip_norm_sh, \"echo 'done!'\"\n",
    "chip_norm_sh.close()\n",
    "subp.call(['chmod','a+x',scripts_dir + 'chip_norm.sh'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use macs2 to call peaks\n",
    "chip_norm_sbatch = open(scripts_dir + \"chip_norm_sbatch.sh\",\"w+\")\n",
    "tacc_dir = \"[FILL_ME_IN]\"\n",
    "tacc_scripts = tacc_dir + \"scripts/\"\n",
    "tacc_h5 = tacc_dir + \"hf5/\"\n",
    "tacc_mapping = tacc_dir + \"mapping/\"\n",
    "tacc_genomes = tacc_dir + \"genomes/\"\n",
    "dm_mfold = (5,10)\n",
    "dp_mfold = (5,10)\n",
    "print >> chip_norm_sbatch, \"#!/bin/bash\"\n",
    "print >> chip_norm_sbatch, \"# SLURM job submission script for chip_norm.sh\"\n",
    "\n",
    "header = \"\"\"#!/bin/bash\n",
    "\n",
    "#####################################\n",
    "#\n",
    "# run chip_tagcount_normalize.py to generate pytables .hf5's for all data \n",
    "#\n",
    "#####################################\n",
    "# Job parameters:\n",
    "#SBATCH -J %s           \n",
    "#SBATCH -o %s.out%%j       \n",
    "#SBATCH -e %s.err%%j \n",
    "#SBATCH -p normal\n",
    "#SBATCH -n 1\n",
    "#SBATCH -t 01:30:00\n",
    "#SBATCH --mail-user=user@nowhere\n",
    "#SBATCH --mail-type=begin  \n",
    "#SBATCH --mail-type=end    \n",
    "\"\"\"\n",
    "\n",
    "for name in to_analyze.keys():\n",
    "    \"\"\"\n",
    "    call_peaks_msh = open(scripts_dir + \"chip_norm_%sm.sh\" % name,\"w+\")\n",
    "    print >> call_peaks_msh, header % (name+\"m\",name+\"m\",name+\"m\")\n",
    "    print >> call_peaks_msh, \"cd %s\" % (tacc_h5,)\n",
    "    print >> call_peaks_msh, \"macs2 callpeak -t %s -c %s -n %s -f SAM -g dm -m %d %d\" % (tacc_h5+name+\"_dmel_aln.sam.gz\",tacc_h5+\"inAll_dmel_aln.sam.gz\",name+\"_dmel\",dm_mfold[0],dm_mfold[1])\n",
    "    call_peaks_msh.close()\n",
    "    print >> call_peaks_sbatch, \"sbatch call_peaks_%sm.sh\" % (name,)\n",
    "    \"\"\"\n",
    "    chip_norm_psh = open(scripts_dir + \"chip_norm_%sp.sh\" % name,\"w+\")\n",
    "    print >> chip_norm_psh, header % (name+\"p\",tacc_h5+name+\"p\",tacc_h5+name+\"p\")\n",
    "    print >> chip_norm_psh, \"cd %s\" % (tacc_h5,)\n",
    "    print >> chip_norm_psh, \"chip_tagcount_normalize.py -n %s -q 30 -e 300 -o -u -z %s %s\" % (tacc_h5+name+\"_dpse\",tacc_genomes+\"dpse.fa\",tacc_mapping+name+\"_dpse_aln.sam.gz\")\n",
    "    chip_norm_psh.close()\n",
    "    print >> chip_norm_sbatch, \"sbatch chip_norm_%sp.sh\" % (name,)\n",
    "\n",
    "chip_norm_sbatch.close()\n",
    "subp.call(['chmod','a+x',scripts_dir + 'chip_norm_sbatch.sh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use macs2 to call peaks\n",
    "call_peaks_sh = open(scripts_dir + \"call_peaks.sh\",\"w+\")\n",
    "dm_mfold = (5,10)\n",
    "dp_mfold = (5,10)\n",
    "header = \"\"\"#!/bin/bash\n",
    "\n",
    "\n",
    "#####################################\n",
    "#\n",
    "# run chip_tagcount_normalize.py to generate pytables .hf5's for all data \n",
    "#\n",
    "\"\"\"\n",
    "print >> call_peaks_sh, header\n",
    "print >> call_peaks_sh, \"cd %s\" % (mapping_dir,)\n",
    "for name in smp_in.keys():\n",
    "    print >> call_peaks_sh, \"echo 'calling peaks for %s...'\" % (name,)\n",
    "    print >> call_peaks_sh, \"macs2 -t %s -c %s -n %s -f SAM -g dm -m %d,%d 1> %s 2> %s\" % (mapping_dir+name+\"_dmel_aln.sam.gz\",mapping_dir+\"inAll_dmel_aln.sam.gz\",name+\"_dmel\",dm_mfold[0],dm_mfold[1],peaks_dir+name+\"_dmel_macs.stdout.txt\",peaks_dir+name+\"_dmel_macs.stderr.txt\")\n",
    "    print >> call_peaks_sh, \"macs2 -t %s -c %s -n %s -f SAM -g 140000000 -m %d,%d 1> %s 2> %s\" % (mapping_dir+name+\"_dpse_aln.sam.gz\",mapping_dir+smp_in[name]+\"_dpse_aln.sam.gz\",name+\"_dpse\",dp_mfold[0],dp_mfold[1],peaks_dir+name+\"_dpse_macs.stdout.txt\",peaks_dir+name+\"_dpse_macs.stderr.txt\")\n",
    "    print >> call_peaks_sh, \"echo 'done!'\"\n",
    "call_peaks_sh.close()\n",
    "subp.call(['chmod','a+x',scripts_dir + 'call_peaks.sh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use macs2 to call peaks\n",
    "call_peaks_sbatch = open(scripts_dir + \"call_peaks_sbatch.sh\",\"w+\")\n",
    "tacc_dir = \"[FILL_ME_IN]\"\n",
    "dm_mfold = (5,10)\n",
    "dp_mfold = (5,10)\n",
    "print >> call_peaks_sbatch, \"#!/bin/bash\"\n",
    "print >> call_peaks_sbatch, \"# SLURM job submission script for call_peaks.sh\"\n",
    "\n",
    "header = \"\"\"#!/bin/bash\n",
    "\n",
    "#####################################\n",
    "#\n",
    "# run chip_tagcount_normalize.py to generate pytables .hf5's for all data \n",
    "#\n",
    "#####################################\n",
    "# Job parameters:\n",
    "#SBATCH -J %s           \n",
    "#SBATCH -o %s.out%%j       \n",
    "#SBATCH -e %s.err%%j \n",
    "#SBATCH -p normal\n",
    "#SBATCH -n 1\n",
    "#SBATCH -t 01:30:00\n",
    "#SBATCH --mail-user=user@nowhere\n",
    "#SBATCH --mail-type=begin  \n",
    "#SBATCH --mail-type=end    \n",
    "\"\"\"\n",
    "\n",
    "for name in smp_in.keys():\n",
    "    call_peaks_msh = open(scripts_dir + \"call_peaks_%sm.sh\" % name,\"w+\")\n",
    "    print >> call_peaks_msh, header % (name+\"m\",name+\"m\",name+\"m\")\n",
    "    print >> call_peaks_msh, \"cd %s\" % (tacc_dir+\"peaks/\",)\n",
    "    print >> call_peaks_msh, \"macs2 callpeak -t %s -c %s -n %s -f SAM -g dm -m %d %d\" % (tacc_dir+'mapping/'+name+\"_dmel_aln.sam.gz\",tacc_dir+'mapping/'+\"inAll_dmel_aln.sam.gz\",name+\"_dmel\",dm_mfold[0],dm_mfold[1])\n",
    "    call_peaks_msh.close()\n",
    "    print >> call_peaks_sbatch, \"sbatch call_peaks_%sm.sh\" % (name,)\n",
    "    call_peaks_psh = open(scripts_dir + \"call_peaks_%sp.sh\" % name,\"w+\")\n",
    "    print >> call_peaks_psh, header % (name+\"p\",name+\"p\",name+\"p\")\n",
    "    print >> call_peaks_psh, \"cd %s\" % (tacc_dir+\"peaks/\",)\n",
    "    print >> call_peaks_psh, \"macs2 callpeak -t %s -c %s -n %s -f SAM -g 140000000 -m %d %d\" % (tacc_dir+'mapping/'+name+\"_dpse_aln.sam.gz\",tacc_dir+'mapping/'+smp_in[name]+\"_dpse_aln.sam.gz\",name+\"_dpse\",dp_mfold[0],dp_mfold[1])\n",
    "    call_peaks_psh.close()\n",
    "    print >> call_peaks_sbatch, \"sbatch call_peaks_%sp.sh\" % (name,)\n",
    "\n",
    "call_peaks_sbatch.close()\n",
    "subp.call(['chmod','a+x',scripts_dir + 'call_peaks_sbatch.sh'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run scripts generated above in this order:\n",
    "      1. `run_bowtie.sh`\n",
    "      2. `grep_dmdp.sh`\n",
    "      3. `chip_norm.sh`\n",
    "      4. `call_peaks.sh` or `call_peaks_sbatch.sh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
