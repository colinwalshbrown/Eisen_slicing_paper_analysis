{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import fasta_subseq_2 as fa\n",
    "import seq_plotmethods as sp\n",
    "import itertools as it\n",
    "import tables as tb\n",
    "import numpy as np\n",
    "import subprocess as subp\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import tarfile\n",
    "import re\n",
    "import patser_tools as pat\n",
    "#import matplotlib_venn as vn \n",
    "import os\n",
    "import shutil\n",
    "from __future__ import division\n",
    "from skimage import io as skio\n",
    "from skimage import transform as skxform\n",
    "\n",
    "# set up plotting environment for LaTeX compatability\n",
    "plt.rc('text', usetex = False)\n",
    "plt.rc('font', family = 'serif')\n",
    "\n",
    "# Define chromosome names for dmel and dpse\n",
    "DMEL_CHRS = ['2L','2R','3L','3R','X','YHet','4','2LHet','2RHet','3LHet','3RHet','XHet','U','Uextra']\n",
    "DMEL_CHRS_EU = ['2L','2R','3L','3R','X']\n",
    "\n",
    "current_dir = \"/Users/barricklab/Dropbox/Documents/Manuscripts/slicing/analysis_notebook/\"\n",
    "genomes_dir = current_dir + \"genomes/\"\n",
    "reads_dir = current_dir + \"reads/\"\n",
    "data_out_dir = current_dir + \"data/\"\n",
    "figs_dir = current_dir + \"figs/\"\n",
    "scripts_dir = current_dir + \"scripts/\"\n",
    "mapping_dir = data_out_dir + \"mapping/\"\n",
    "peaks_dir = data_out_dir + \"peaks/\"\n",
    "h5_dir = data_out_dir + \"hf5/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rebuilding index...\n"
     ]
    }
   ],
   "source": [
    "# From Previous Fig. 5\n",
    "dm_fa = fa.FastaDB(\"/Users/barricklab/Dropbox/Documents/Manuscripts/slicing/analysis_notebook/genomes/dmel.fa\")\n",
    "\n",
    "def summit_window_seq(name,peaks,win,genome):\n",
    "    # write sequences to fasta for MEME analysis\n",
    "    wd = \"/Users/cwbrown/Dropbox/Documents/Manuscripts/slicing/Figures/Fig5_sequence_correlates/meme_seqs/\"\n",
    "    seq_out = open(\"%s%s_win%d_seqs.fa\" % (wd,name,win),\"w\")\n",
    "    for p in peaks:\n",
    "        start = p['summit'] - int(win/2)\n",
    "        end = p['summit'] + win - int(win/2) \n",
    "        seq = genome[p['chr']][start:end]\n",
    "        print >> seq_out, \">%s_%d-%d %s\\n%s\" % (p['chr'],start,end,name,seq)\n",
    "\n",
    "def pks_patser_hits_rebuild(pks,matrix_file,fastadb,flank=0,patser_cutoff=None):\n",
    "     \n",
    "    phits = pd.DataFrame(columns=[\"matrix\",\"parent_start\",\"parent_end\",\"parent_chr\",\"parent_summit\",\"motif_start\",\"motif_end\",\"pval_cutoff\",\"pval\",\"score\",\"score_cutoff\",\"strand\"])\n",
    "    # concatenate peak sequences\n",
    "    all_seqs = \"\"\n",
    "    seq_idx = []\n",
    "    cur_len = 0\n",
    "    for p in pks:\n",
    "        seq = fastadb[p['chr']][p['start']:p['end']]\n",
    "        seq_coords = (cur_len,cur_len+len(seq))\n",
    "        all_seqs = all_seqs + seq\n",
    "        cur_len += len(seq)\n",
    "        seq_idx.append(seq_coords)\n",
    "    print len(all_seqs)\n",
    "    \n",
    "    p_annot = pat.makePatserAnnotation(sequence=all_seqs,matrix=matrix_file,scorecut=patser_cutoff)\n",
    "    p_sites = p_annot.getFeaturesByType('BindingSiteFeature')\n",
    "    [s.tags.update({'pval':None,'pvalcut':None}) for s in p_sites if 'pval' not in s.tags.keys()]\n",
    "    p_sites_dict = [{'matrix':s.tags['motif_name'],\n",
    "                         'parent_start':None,\n",
    "                         'parent_end':None,\n",
    "                         'parent_chr':None,\n",
    "                         'parent_summit':None,\n",
    "                         'motif_start':s.start,\n",
    "                         'motif_end':s.end,\n",
    "                         'pval_cutoff':s.tags['pvalcut'],\n",
    "                         'pval':s.tags['pval'],\n",
    "                         'score':s.tags['score'],\n",
    "                         'score_cutoff':s.tags['scorecut'],\n",
    "                         'strand':s.tags['strand']} for s in p_sites]\n",
    "    p_sites_lists = {}\n",
    "    for k in p_sites_dict[0].keys():\n",
    "        p_sites_lists[k] = [x[k] for x in p_sites_dict]\n",
    "    phits_raw = pd.DataFrame(data=p_sites_lists)\n",
    "    print \"sites =%d,%d\" % (phits_raw.shape[0],phits_raw.shape[1])\n",
    "    for (i,(st,end)) in enumerate(seq_idx):\n",
    "        seq_hits = phits_raw[(phits_raw['motif_start'] >= st) &\n",
    "                             (phits_raw['motif_end'] <= end)]\n",
    "        p = pks[i]\n",
    "        if len(seq_hits) > 0:\n",
    "            seq_hits['motif_start'] = seq_hits['motif_start'] - st\n",
    "            seq_hits['motif_end'] = seq_hits['motif_end'] - st\n",
    "            seq_hits['parent_start'] = p['start']\n",
    "            seq_hits['parent_end'] = p['end']\n",
    "            seq_hits['parent_chr'] = p['chr']\n",
    "            seq_hits['parent_summit'] = p['summit']\n",
    "            #print \"%s:%d-%d %d hits\" % (p['chr'],p['start'],p['end'],seq_hits.shape[0])\n",
    "            phits = phits.append(seq_hits,ignore_index=True)\n",
    "    return phits\n",
    "\n",
    "def pks_patser_hits(pks,matrix_file,fastadb,flank=0,patser_cutoff=None):\n",
    "    phits = pd.DataFrame(columns=[\"matrix\",\"parent_start\",\"parent_end\",\"parent_chr\",\"motif_start\",\"motif_end\",\"pval_cutoff\",\"pval\",\"score\",\"score_cutoff\",\"strand\"])\n",
    "    for p in pks:\n",
    "        seq = fastadb[p['chr']][p['start']:p['end']]\n",
    "        p_annot = pat.makePatserAnnotation(sequence=seq,matrix=matrix_file,scorecut=patser_cutoff)\n",
    "        p_sites = p_annot.getFeaturesByType('BindingSiteFeature')\n",
    "        [s.tags.update({'pval':None,'pvalcut':None}) for s in p_sites if 'pval' not in s.tags.keys()]\n",
    "        p_sites_dict = [{'matrix':s.tags['motif_name'],\n",
    "                         'parent_start':p['start'],\n",
    "                         'parent_end':p['end'],\n",
    "                         'parent_chr':p['chr'],\n",
    "                         'motif_start':s.start,\n",
    "                         'motif_end':s.end,\n",
    "                         'pval_cutoff':s.tags['pvalcut'],\n",
    "                         'pval':s.tags['pval'],\n",
    "                         'score':s.tags['score'],\n",
    "                         'score_cutoff':s.tags['scorecut'],\n",
    "                         'strand':s.tags['strand']} for s in p_sites]\n",
    "        if len(p_sites_dict) > 0:\n",
    "            p_sites_lists = {}\n",
    "            for k in p_sites_dict[0].keys():\n",
    "                p_sites_lists[k] = [x[k] for x in p_sites_dict]\n",
    "            #print len(p_sites_lists)\n",
    "            phits = phits.append(pd.DataFrame(data=p_sites_lists),ignore_index=True)\n",
    "            #print phits.shape\n",
    "        \"\"\"\n",
    "'pval_cutoff':s.tags['pvalcut'],\n",
    "                         'pval':s.tags['pval'],\n",
    "{'matwidth': 11, 'motif_name': 'hb_SOLEXA_5', 'pvalcut': -8.947, 'pval': -5.89, 'score': 1.23, 'scorecut': 0.0, 'strand': '+'}\n",
    "        r_sites = []\n",
    "        l_sites = []\n",
    "        if flank > 0:\n",
    "            l_fl_seq = fastadb[p['chr']][p['start']-flank:p['start']]\n",
    "            r_fl_seq = fastadb[p['chr']][p['end']:p['end']+flank]\n",
    "            l_annot = pat.makePatserAnnotation(sequence=l_fl_seq,matrix=matrix_file, scorecut=patser_cutoff)\n",
    "            r_annot = pat.makePatserAnnotation(sequence=rl_fl_seq,matrix=matrix_file, scorecut=patser_cutoff)\n",
    "            l_sites = l_annot.getFeaturesByType('BindingSiteFeature')\n",
    "            r_sites = l_annot.getFeaturesByType('BindingSiteFeature')\n",
    "        phits.append(p_sites)\n",
    "        \"\"\"\n",
    "    return phits\n",
    "\n",
    "\n",
    "def build_nmer_profile(pks,win,n,fastadb):\n",
    "    bases = ['A','T','G','C']\n",
    "    rc = {'A':'T','C':'G','G':'C','T':'A'}\n",
    "    nmer_decode_pr = it.product(bases,repeat=n)\n",
    "    stop = False\n",
    "    nmer_decode = []\n",
    "    while not stop:\n",
    "        try:\n",
    "            nmer = nmer_decode_pr.next()\n",
    "            nmer_rc = [rc[x] for x in reversed(nmer)]\n",
    "            if \"\".join(nmer_rc) not in nmer_decode:\n",
    "                nmer_decode.append(\"\".join(nmer))\n",
    "        except StopIteration:\n",
    "            stop = True\n",
    "    #print len(nmer_decode)\n",
    "    nmer_code = dict([(x,i) for (i,x) in enumerate(nmer_decode)])\n",
    "    print len(nmer_code)\n",
    "    nmer_code.update([(x,i) for (i,x) in enumerate([\"\".join([rc[y] for y in reversed(list(z))]) for z in nmer_decode])])\n",
    "    print len(nmer_code)\n",
    "    #print nmer_code\n",
    "    #print nmer_code['CCCCCA']\n",
    "    #print nmer_decode[4095]\n",
    "    print nmer_code\n",
    "    profiles = []\n",
    "    locations = []\n",
    "    totals = np.zeros(len(nmer_decode))\n",
    "    for p in pks:\n",
    "        nmer_ar = np.zeros(len(nmer_decode))\n",
    "        seq = fastadb[p['chr']][p['summit']-int(win/2):p['summit']+int(win/2)]\n",
    "            \n",
    "        for i in range(0,len(seq)-(n-1)):\n",
    "            subseq = seq[i:i+n]\n",
    "            if re.search('[^ACGTacgt]',subseq):\n",
    "                continue\n",
    "            nmer_ar[nmer_code[subseq]] += 1\n",
    "        profiles.append(nmer_ar)\n",
    "        totals += nmer_ar\n",
    "    return (np.array(profiles), totals,nmer_decode)\n",
    "\n",
    "def correlate_nmers(peaks,win,fdr,rand_reps,n,sort_by):\n",
    "    sorted_rows = sp.plot_by_diff_rank(False,sort_by,False,peaks,ant_w1_norm,pst_w1_norm,wh1_w1_norm)\n",
    "    sorted_peaks = [x[0] for x in sorted_rows]\n",
    "    diff_scrs = np.array([x[1] for x in sorted_rows])\n",
    "    (nmers,profile,decode) = build_nmer_profile(sorted_peaks,win,n,dm_fa)\n",
    "    print len(decode)\n",
    "    significant = []\n",
    "    all_nmer_corr = []\n",
    "    fdr_cutoffs = []\n",
    "    rand_sets_mtx = np.zeros((len(diff_scrs),rand_reps))\n",
    "    rand_set_linfit = np.zeros((len(decode),rand_reps))\n",
    "    for x in range(0,rand_reps):\n",
    "        if (x % 1000) == 0:\n",
    "            print \"%d random sets\" % x\n",
    "        rand_sets_mtx[:,x] = np.random.permutation(diff_scrs)\n",
    "        \n",
    "    for (i,nmer) in enumerate(decode):\n",
    "        nmer_counts = nmers[:,i]\n",
    "        #corr = np.corrcoef(np.array([nmer_counts,rset]))[0,1]\n",
    "        #rand_set_corr[i].append(corr)\n",
    "        nmer_mtx = np.vstack([nmer_counts,np.ones(len(nmer_counts))]).T\n",
    "        linfit = np.linalg.lstsq(nmer_mtx,rand_sets_mtx)\n",
    "        coeffs = linfit[0][0]\n",
    "        rand_set_linfit[i,:] = coeffs\n",
    "        #fdr_ucut = np.percentile(coeffs,100-(fdr/2.0))\n",
    "        #fdr_lcut = np.percentile(coeffs,fdr/2.0)\n",
    "        q1 = np.percentile(coeffs,25)\n",
    "        q3 = np.percentile(coeffs,75)\n",
    "        #plt.subplot(5,1,i)\n",
    "        #plt.hist(coeffs,bins=100)\n",
    "        #plt.axvline(fdr_cut)\n",
    "        #plt.axvline(-fdr_cut)\n",
    "        (sample_m,sample_c) = np.linalg.lstsq(nmer_mtx,diff_scrs)[0]\n",
    "        l_pval = (len(np.where(coeffs <= sample_m)[0])/len(coeffs))*2 # pval = density of emp dist below sample m, x2 since two-tailed test\n",
    "        h_pval = (len(np.where(coeffs >= sample_m)[0])/len(coeffs))*2 # pval = density of emp dist below sample m, x2 since two-tailed test\n",
    "        empirical_pval = min((l_pval,h_pval))\n",
    "        (ntest_stat,ntest_pval) = stats.normaltest(coeffs)\n",
    "        gkde=stats.gaussian_kde(coeffs)\n",
    "        l_cont_pval = gkde.integrate_box_1d(-inf,sample_m) * 2\n",
    "        h_cont_pval = gkde.integrate_box_1d(sample_m,inf) * 2\n",
    "        kde_pval = min([l_cont_pval,h_cont_pval])\n",
    "        linreg_pval = stats.linregress(nmer_counts,diff_scrs)[3]\n",
    "        #if ((i % 10 == 0) in range(5)) and (i <=50):\n",
    "        #    gkde=stats.gaussian_kde(coeffs)\n",
    "        #    plt.subplot(5,1,(i/10))\n",
    "        #    plt.hist(coeffs,bins=50,normed=True)\n",
    "        #    s_pts = np.linspace(min(coeffs)-1,max(coeffs)+1)\n",
    "        #    s_pts_pdf = gkde.evaluate(s_pts)\n",
    "        #    plt.plot(s_pts,s_pts_pdf,\"r-\",label='Gaussian KDE')\n",
    "        #    plt.plot(s_pts,stats.norm.pdf(s_pts),'g-',label=\"Normal\")\n",
    "        #    plt.axvline(sample_m)\n",
    "        #    plt.legend()\n",
    "        #if (sample_m > fdr_ucut) or (sample_m < fdr_lcut):\n",
    "        #    print \"SIGNIFICANT NMER: id:%d seq:%s Rsq:%f ucut:%f lcut:%f\" % (i,nmer,sample_m,fdr_ucut,fdr_lcut)\n",
    "        #    significant.append((i,nmer,sample_m,sample_c,nmer_counts,diff_scrs))\n",
    "        if i % 200 == 0:\n",
    "            print \"%d %s sample_m: %f emp_pval: %f kde_pval: %f linreg_pval: %f normaltest_stat: %f normaltest pvalue: %f\" % (i,nmer,sample_m,empirical_pval,kde_pval,linreg_pval,ntest_stat,ntest_pval)\n",
    "        all_nmer_corr.append((kde_pval,empirical_pval,linreg_pval,ntest_pval,nmer,sample_m,nmer_counts))\n",
    "    all_corr_sorted_emp = sorted(all_nmer_corr,cmp=(lambda x,y:cmp(y[0],x[0])))\n",
    "    all_corr_sorted_kde = sorted(all_nmer_corr,cmp=(lambda x,y:cmp(y[1],x[1])))\n",
    "    all_corr_sorted_linreg = sorted(all_nmer_corr,cmp=(lambda x,y:cmp(y[2],x[2])))\n",
    "    m = len(all_corr_sorted_kde)\n",
    "    significant_emp = [x for (i,x) in enumerate(all_corr_sorted_emp) if x[0] < ((float(i)/m)*fdr)]\n",
    "    significant_kde = [x for (i,x) in enumerate(all_corr_sorted_kde) if x[0] < ((float(i)/m)*fdr)]\n",
    "    significant_linreg = [x for (i,x) in enumerate(all_corr_sorted_linreg) if x[0] < ((float(i)/m)*fdr)]\n",
    "    #all_nmer_cnt_sorted = np.array([x[1] for x in all_corr_sorted]).T\n",
    "    #plt.imshow(all_nmer_cnt_sorted,cmap='Greys',aspect='auto',interpolation='none') \n",
    "    return ((significant_emp,significant_kde,significant_linreg),(all_corr_sorted_emp,all_corr_sorted_kde,all_corr_sorted_linreg),diff_scrs)\n",
    "    #return (significant_kde,all_corr_sorted_kde,diff_scrs)\n",
    "\n",
    "    #if corr == 1.0:\n",
    "        #    print \"corr %s == 1.0\" % (nmer,)\n",
    "        #    print \"nmer_counts: %s\" % (str(nmer_counts),)\n",
    "        #    print \"rand_set   : %s\" % (str(rset),)\n",
    "        \n",
    "def parse_motif_file(mot_file,out_dir):\n",
    "    motifs = {}\n",
    "    #cur_TF = None\n",
    "    cur_out = None\n",
    "    cur_out_fh = None\n",
    "    for ln in open(mot_file):\n",
    "        TF_search = re.search(\"^>((\\S+?)_\\S+)\",ln)\n",
    "        if TF_search:\n",
    "            print cur_out\n",
    "            cur_mot = TF_search.group(1)\n",
    "            cur_TF = TF_search.group(2).upper()\n",
    "            cur_out = os.path.join(motif_dir,cur_mot + \".mtx\")\n",
    "            \n",
    "            if cur_TF in motifs.keys():\n",
    "                motifs[cur_TF][cur_mot] = {'matrix_file':cur_out}\n",
    "            else:\n",
    "                motifs[cur_TF] = {cur_mot :{'matrix_file':cur_out}}\n",
    "                \n",
    "            cur_out_fh = open(cur_out,\"w\")\n",
    "            \n",
    "        elif cur_out_fh:\n",
    "            print >> cur_out_fh, ln[:-1]\n",
    "    return motifs\n",
    "    \n",
    "def parse_motif_seq_file(mot_file,out_dir):\n",
    "    motifs = {}\n",
    "    #cur_TF = None\n",
    "    cur_out = None\n",
    "    cur_out_fh = None\n",
    "    for ln in open(mot_file):\n",
    "        TF_search = re.search(\"^(\\S*)\\s+(\\S+)\\s+\\>$\",ln)\n",
    "        if TF_search:\n",
    "            cur_mot = TF_search.group(2)\n",
    "            cur_TF = re.search(\"(^\\S+?)_\",cur_mot).group(1).upper()\n",
    "            cur_out = os.path.join(motif_dir,cur_mot + \".fa\")\n",
    "            if cur_TF in motifs.keys():\n",
    "                motifs[cur_TF][cur_mot] = {'sequences_file':cur_out}\n",
    "            else:\n",
    "                motifs[cur_TF]= {cur_mot: {'sequences_file':cur_out}}\n",
    "            cur_out_fh = open(cur_out,\"w\")\n",
    "            print \"==== %s:%s:%s\" % (cur_TF,cur_mot,cur_out)\n",
    "            #print file_search.group(2)\n",
    "            #print >> cur_out_fh, file_search.group(2)\n",
    "        elif (cur_out and cur_out_fh):\n",
    "            wrote = 1\n",
    "            print >> cur_out_fh, ln,\n",
    "    cur_out_fh.close()\n",
    "    return motifs\n",
    "\n",
    "def build_motifs(mot_dict,out_dir):\n",
    "    for TF in mot_dict.keys():\n",
    "        for (mot,f) in mot_dict[TF].items():\n",
    "            in_seq_fh = open(f[\"sequences_file\"]).read()\n",
    "            out_seqs = re.subn(\"\\>(\\S+)\\n(\\S+\\n)\",_filter_gaps,in_seq_fh)\n",
    "            out_seq_fh = open(os.path.join(out_dir,mot + \".spf\"),\"w+\")\n",
    "            out_seq_fh.write(out_seqs[0])\n",
    "            out_seq_fh.close()\n",
    "        \n",
    "            pat_in_file = os.path.join(out_dir,mot + \".spf\")\n",
    "            pat_stdout_file = os.path.join(out_dir,mot + \".mtx\")\n",
    "            pat_stderr_file = os.path.join(out_dir,mot + \".err\")\n",
    "            run_make_matrix = subp.call(\"make-matrix -A C:G 1 A:T 1 < %s 1> %s 2> %s\" % (pat_in_file,pat_stdout_file,pat_stderr_file),shell=True)\n",
    "            #(pat_out,pat_out_stderr) = run_make_matrix.communicate(input=pat_in_file)\n",
    "            #(pat_out,pat_out_stderr) = run_make_matrix.communicate()\n",
    "            if run_make_matrix != 0:\n",
    "                print \"ERROR: %s\\t%s\" % (mot,run_make_matrix)\n",
    "            else:\n",
    "                mot_dict[TF][mot]['matrix_file'] = pat_stdout_file\n",
    "    return mot_dict\n",
    " \n",
    "def _filter_gaps(m):\n",
    "    r = m.group(1) + \" \" + m.group(2)\n",
    "    if (\"-\" in m.group(2)) or (\"N\" in m.group(2)):\n",
    "        r = \"\"\n",
    "    return r\n",
    "\n",
    "def pat_hit_motif_dict(motif_dict,peaks,filter_by=\"\"):\n",
    "    all_tfs = []\n",
    "    motif_tot = len(motif_dict.keys())\n",
    "    for (i,TF) in enumerate(motif_dict.keys()):\n",
    "        print \"%d / %d TFs Scanning\" % (i,motif_tot)\n",
    "        for mot in motif_dict[TF].keys():\n",
    "            if (filter_by and (filter_by in mot)) or (not filter_by):\n",
    "                print \"Getting hits for %s:%s...\" % (TF,mot),\n",
    "                if 'matrix_file' not in motif_dict[TF][mot]:\n",
    "                    continue\n",
    "                hit_table = pks_patser_hits_rebuild(peaks,motif_dict[TF][mot]['matrix_file'],dm_fa,patser_cutoff=0.0)   \n",
    "                if hit_table.shape[0] == 0:\n",
    "                    continue\n",
    "                hit_table[\"TF\"] = TF\n",
    "                all_tfs.append(hit_table)\n",
    "                hit_table_cutoff = hit_table[hit_table.pval < hit_table.pval_cutoff]\n",
    "                \n",
    "                print \"%d hits, %d below cutoff (%f), overall mean score: %f, pass cutoff mean score %f\" % (hit_table.shape[0],hit_table_cutoff.shape[0],hit_table.pval_cutoff[0],hit_table['score'].median(),hit_table_cutoff['score'].median())\n",
    "    all_tfs_df = pd.concat(all_tfs)\n",
    "    return all_tfs_df\n",
    "\n",
    "class chipExpt():\n",
    "    def __init__(self,group,name=\"NoName\",chrs=DMEL_CHRS_EU,chr_ext='ext'):\n",
    "        self.chr_dict = {}\n",
    "        self.group = group\n",
    "        self.name = name\n",
    "        arrays = group._v_children.items()\n",
    "        if chrs:\n",
    "            for ch in chrs:\n",
    "                chr_found = 0\n",
    "                for (name,node) in arrays:\n",
    "                    if re.search(chr_ext + \"\\w*_(chr)?\"+ch+\"$\",name):\n",
    "                        #print (ch,name,node.name)\n",
    "                        chr_found = 1\n",
    "                        self.chr_dict[ch] = node\n",
    "                        break\n",
    "                if chr_found == 0:\n",
    "                    print \"no chr found for %s\" % (ch,)\n",
    "        else:\n",
    "            for n in group._f_walkNodes():\n",
    "                ch_s = re.search(\"chr(.+)\",n.name)\n",
    "                self.chr_dict[ch_s.group(1)] = n\n",
    "                break\n",
    "                    \n",
    "    def __getitem__(self,item):\n",
    "        return self.chr_dict[item]\n",
    "\n",
    "    def write_wig(self,chr_convert=None,span=10,outfile=None):\n",
    "        if outfile == None:\n",
    "            outfile = self.name + \".wig\"\n",
    "        wigout = open(outfile,\"w\")\n",
    "        print >> wigout, \"track type=wiggle_0 name=%s description=%s visibility=full autoScale=off maxHeightPixels=100:50:20\" % (self.name,self.name)\n",
    "        for (chrom,chr_arr) in self.chr_dict.items():\n",
    "            print \"Writing %s...\" % (chrom,),\n",
    "            name = chrom\n",
    "            if chr_convert != None:\n",
    "                name = chr_convert[chrom]\n",
    "            print >> wigout, \"variableStep chrom=%s span=%d\" % (name,span)\n",
    "            for i in np.arange(1,len(chr_arr),step=span):\n",
    "                print >> wigout, \"%d\\t%f\" % (i,np.sum(chr_arr[i:i+span])/float(span))\n",
    "            print \"done!\"\n",
    "        wigout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: group 'macs_peaks' exists!\n",
      "WARNING: group 'macs_peaks' exists!\n",
      "WARNING: group 'macs_peaks' exists!\n",
      "WARNING: group 'macs_peaks' exists!\n",
      "Peak window (peak width +/- 0)\n",
      "Starting Sets:\n",
      "\tgtAm :     3000 peaks\n",
      "\tgtPm :      915 peaks\n",
      "\tgtCm :     1870 peaks\n",
      "\tgtW1m :     1629 peaks\n",
      "\tgtW2m :     1557 peaks\n",
      "8971 total peaks in starting set\n",
      "3333 in union, 2022 in intersect\n",
      "final isct: 2022 before filtering, 2022 after\n",
      "total overlapping peaks (all sets): 4044\n",
      "By-Experiment Overlap Counts:\n",
      "\tgtPm :      165\n",
      "\tgtCm :     1054\n",
      "\tgtW2m :      380\n",
      "\tgtW1m :      745\n",
      "\tgtAm :     1700\n",
      "GT Dmel Final 5-way overlaps: 634\n"
     ]
    }
   ],
   "source": [
    "gff_h5 = h5_dir + \"/gff.h5\"\n",
    "gff_dmel = sp.GFFtable(genomes_dir + \"/dmel-all-r5.17_genes.gff\",gff_h5,DMEL_CHRS_EU,\"gene\")\n",
    "# giant ChIP\n",
    "gtAm_h5 = tb.open_file(h5_dir+'gtA_dmel.h5', mode='r+')\n",
    "gtPm_h5 = tb.open_file(h5_dir+'gtP_dmel.h5', mode='r+')\n",
    "gtCm_h5 = tb.open_file(h5_dir+'gtC_dmel.h5', mode='r+')\n",
    "gtW1m_h5 = tb.open_file(h5_dir+'gtW1_dmel.h5', mode='r+')\n",
    "gtW2m_h5 = tb.open_file(h5_dir+'gtW2_dmel.h5', mode='r+')\n",
    "\n",
    "# Load dmel input data - concatenated reads from all input samples\n",
    "inAllm_h5 = tb.open_file(h5_dir+'inAll_dmel.h5', mode='r+')\n",
    "\n",
    "# make chipExpt objects for all above (tag-normed and raw counts)\n",
    "gtAm_tn = chipExpt(gtAm_h5.root.tag_counts.ext_tags,\"Dmel Ant GT ChIP, tag-normalized\")\n",
    "gtPm_tn = chipExpt(gtPm_h5.root.tag_counts.ext_tags,\"Dmel Post GT ChIP, tag-normalized\")\n",
    "gtCm_tn = chipExpt(gtCm_h5.root.tag_counts.ext_tags,\"Dmel Combo GT ChIP, tag-normalized\")\n",
    "gtW1m_tn = chipExpt(gtW1m_h5.root.tag_counts.ext_tags,\"Dmel Whole Rep1 GT ChIP, tag-normalized\")\n",
    "gtW2m_tn = chipExpt(gtW2m_h5.root.tag_counts.ext_tags,\"Dmel Whole Rep2 GT ChIP, tag-normalized\")\n",
    "\n",
    "# Load Peak Data\n",
    "try:\n",
    "    pks_h5 = tb.open_file(peaks_dir+\"/peaks.h5\",\"w\")\n",
    "except ValueError:\n",
    "    pks_h5.close()\n",
    "    pks_h5 = tb.open_file(peaks_dir+\"/peaks.h5\",\"w\")\n",
    "\n",
    "# GT peaks    \n",
    "gtAm_pks_tb = sp.read_macs(pks_h5,peaks_dir+\"gtA_dmel_peaks.xls\",expt_name=\"gtAm_pks\")\n",
    "gtPm_pks_tb = sp.read_macs(pks_h5,peaks_dir+\"gtP_dmel_peaks.xls\",expt_name=\"gtPm_pks\")\n",
    "gtCm_pks_tb = sp.read_macs(pks_h5,peaks_dir+\"gtC_dmel_peaks.xls\",expt_name=\"gtCm_pks\")\n",
    "gtW1m_pks_tb = sp.read_macs(pks_h5,peaks_dir+\"gtW1_dmel_peaks.xls\",expt_name=\"gtW1m_pks\")\n",
    "gtW2m_pks_tb = sp.read_macs(pks_h5,peaks_dir+\"gtW2_dmel_peaks.xls\",expt_name=\"gtW2m_pks\")\n",
    "\n",
    "gtAm_pks = [x for x in sp.pks_to_dict(gtAm_pks_tb) if x['chr'] in DMEL_CHRS_EU]\n",
    "gtPm_pks = [x for x in sp.pks_to_dict(gtPm_pks_tb) if x['chr'] in DMEL_CHRS_EU]\n",
    "gtCm_pks = [x for x in sp.pks_to_dict(gtCm_pks_tb) if x['chr'] in DMEL_CHRS_EU]\n",
    "gtW1m_pks = [x for x in sp.pks_to_dict(gtW1m_pks_tb) if x['chr'] in DMEL_CHRS_EU]\n",
    "gtW2m_pks = [x for x in sp.pks_to_dict(gtW2m_pks_tb) if x['chr'] in DMEL_CHRS_EU]\n",
    "\n",
    "(gtm_un0_pks,gtm_in0_pks,gtm_OL0_pks) = sp.peak_union(0,0,['gtAm','gtPm','gtCm','gtW1m','gtW2m'],True,gtAm_pks,gtPm_pks,gtCm_pks,gtW1m_pks,gtW2m_pks)\n",
    "gtm_5wy_OLs = [x for x in gtm_in0_pks if len(set(x['sets'])) == 5]\n",
    "print \"GT Dmel Final 5-way overlaps: %d\" % (len(gtm_5wy_OLs))\n",
    "\n",
    "# Get matching peak sets from each GT dataset\n",
    "(top1000gtW1m_5wy_OL_pi,top1000gtW1m_5wy_OL) = zip(*sp.get_top_n_peaks(1000,gtm_5wy_OLs,gtW1m_tn))\n",
    "gtAm_top1000gtW1m_5OL_tn = sp.make_array_from_peaks('ns',top1000gtW1m_5wy_OL,gtAm_tn)\n",
    "gtPm_top1000gtW1m_5OL_tn = sp.make_array_from_peaks('ns',top1000gtW1m_5wy_OL,gtPm_tn)\n",
    "gtW1m_top1000gtW1m_5OL_tn = sp.make_array_from_peaks('ns',top1000gtW1m_5wy_OL,gtW1m_tn)\n",
    "gtW2m_top1000gtW1m_5OL_tn = sp.make_array_from_peaks('ns',top1000gtW1m_5wy_OL,gtW2m_tn)\n",
    "gtCm_top1000gtW1m_5OL_tn = sp.make_array_from_peaks('ns',top1000gtW1m_5wy_OL,gtCm_tn)\n",
    "\n",
    "# Get 5-way union peak sets from each GT experiment\n",
    "gtAm_5un_tn = sp.make_array_from_peaks('ns',gtm_un0_pks,gtAm_tn)\n",
    "gtPm_5un_tn = sp.make_array_from_peaks('ns',gtm_un0_pks,gtPm_tn)\n",
    "gtW1m_5un_tn = sp.make_array_from_peaks('ns',gtm_un0_pks,gtW1m_tn)\n",
    "gtW2m_5un_tn = sp.make_array_from_peaks('ns',gtm_un0_pks,gtW2m_tn)\n",
    "gtCm_5un_tn = sp.make_array_from_peaks('ns',gtm_un0_pks,gtCm_tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gtA_APfdr1_pks = pd.read_csv(data_out_dir + '/supp_data/gtA_fdr1_pkbind.tsv',delimiter='\\t')\n",
    "gtP_APfdr1_pks = pd.read_csv(data_out_dir + '/supp_data/gtP_fdr1_pkbind.tsv',delimiter='\\t')\n",
    "gtNoBias_highbind_pks = pd.read_csv(data_out_dir + '/supp_data/gtALL_fdr1_notcp_highpkbind.tsv',delimiter='\\t')\n",
    "gtBias_APfdr1_pks = gtA_APfdr1_pks.append(gtP_APfdr1_pks,ignore_index=True)\n",
    "gtALL_highbind_pks = gtBias_APfdr1_pks.append(gtNoBias_highbind_pks,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"# Uncomment and run to generate motif dataframes\n",
    "\"\"\"\n",
    "gtA_B1HTF_sites = pat_hit_motif_dict(motif_locs,gtA_subtr_fdr1_pk,filter_by='SOLEXA')\n",
    "gtA_B1HTF_sites.to_csv(\"/Users/cwbrown/Dropbox/Documents/Manuscripts/slicing/analysis_notebook/data/motifs/gtA_B1HTF_sites.csv\")\n",
    "\n",
    "gtP_B1HTF_sites = pat_hit_motif_dict(motif_locs,gtP_subtr_fdr1_pk,filter_by='SOLEXA')\n",
    "gtP_B1HTF_sites.to_csv(\"/Users/cwbrown/Dropbox/Documents/Manuscripts/slicing/analysis_notebook/data/motifs/gtP_B1HTF_sites.csv\")\n",
    "\n",
    "gtND_B1HTF_sites = pat_hit_motif_dict(motif_locs,[x[6] for x in fdr1_notcp_highpkbind],filter_by='SOLEXA')\n",
    "gtND_B1HTF_sites.to_csv(\"/Users/cwbrown/Dropbox/Documents/Manuscripts/slicing/analysis_notebook/data/motifs/gtND_B1HTF_sites.csv\")\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "gtA_B1HTF_sites = pd.read_csv(\"/Users/cwbrown/Dropbox/Documents/Manuscripts/slicing/analysis_notebook/data/motifs/gtA_B1HTF_sites.csv\")\n",
    "gtP_B1HTF_sites = pd.read_csv(\"/Users/cwbrown/Dropbox/Documents/Manuscripts/slicing/analysis_notebook/data/motifs/gtP_B1HTF_sites.csv\")\n",
    "gtND_B1HTF_sites = pd.read_csv(\"/Users/cwbrown/Dropbox/Documents/Manuscripts/slicing/analysis_notebook/data/motifs/gtND_B1HTF_sites.csv\")\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "#APNDpks = list(gtA_subtr_fdr1_pk) + list(gtP_subtr_fdr1_pk) + [x[6] for x in fdr1_notcp_highpkbind]\n",
    "#print \"A: %d P: %d ND: %d Tot: %d\" % (len(gtA_subtr_fdr1_pk),len(gtP_subtr_fdr1_pk),len(fdr1_notcp_highpkbind),len(APNDpks))\n",
    "#notAPNDpks = [x for x in gtm_un0_pks if x not in APNDpks]\n",
    "gtAll_B1HTF_sites = pat_hit_motif_dict(motif_locs,gtm_un0_pks,filter_by='SOLEXA')\n",
    "#gtAll_B1HTF_sites = pd.concat([gtAll_B1HTF_sites,gtA_B1HTF_sites,gtP_B1HTF_sites,gtND_B1HTF_sites],ignore_index=True)\n",
    "gtAll_B1HTF_sites.to_csv(\"/Users/cwbrown/Dropbox/Documents/Manuscripts/slicing/analysis_notebook/data/motifs/gtAll_B1HTF_sites.csv\")\n",
    "\n",
    "gtAll_B1HTF_sites = pd.DataFrame.from_csv(\"/Users/cwbrown/Dropbox/Documents/Manuscripts/slicing/analysis_notebook/data/motifs/gtAll_B1HTF_sites.csv\")\n",
    "print gtAll_B1HTF_sites.head()\n",
    "gtAll_B1HTF_sites = pat_hit_motif_dict(motif_locs,gtm_un0_pks)\n",
    "gtAll_B1HTF_sites.columns = pd.Index(['matrix','motif_end','motif_start','chr','end','start','summit','pval','pval_cutoff','score','score_cutoff','strand','TF'])\n",
    "gtAll_B1HTF_sites.to_csv(\"/Users/cwbrown/Dropbox/Documents/Manuscripts/slicing/analysis_notebook/data/motifs/gtAll_B1HTF_sites_2.csv\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    matrix  motif_end  motif_start CHR   END  START  SUMMIT  \\\n",
      "0  Espl_FlyReg_FBgn0000591         69           57  2L  6062   5699    5892   \n",
      "1  Espl_FlyReg_FBgn0000591         82           70  2L  6062   5699    5892   \n",
      "2  Espl_FlyReg_FBgn0000591        100           88  2L  6062   5699    5892   \n",
      "3  Espl_FlyReg_FBgn0000591        124          112  2L  6062   5699    5892   \n",
      "4  Espl_FlyReg_FBgn0000591        156          144  2L  6062   5699    5892   \n",
      "\n",
      "   pval  pval_cutoff  score  score_cutoff strand    TF  \n",
      "0 -4.20       -5.305   1.34           0.0      +  ESPL  \n",
      "1 -4.12       -5.305   1.07           0.0      -  ESPL  \n",
      "2 -3.88       -5.305   0.75           0.0      -  ESPL  \n",
      "3 -3.67       -5.305   0.39           0.0      +  ESPL  \n",
      "4 -3.88       -5.305   0.75           0.0      -  ESPL  \n"
     ]
    }
   ],
   "source": [
    "gtAll_B1HTF_sites = pd.read_csv(\"/Users/barricklab/Dropbox/Documents/Manuscripts/slicing/analysis_notebook/data/motifs/gtAll_B1HTF_sites_2.csv\",\\\n",
    "                                header=0,\\\n",
    "                                names=['matrix','motif_end','motif_start','CHR','END','START','SUMMIT','pval','pval_cutoff','score','score_cutoff','strand','TF'])\n",
    "print gtAll_B1HTF_sites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            128up\n",
      "1    14-3-3epsilon\n",
      "2       14-3-3zeta\n",
      "3            140up\n",
      "4              18w\n",
      "Name: NAME, dtype: object\n",
      "            NAME CHR       BEG       END   CLASS      F10     F11      F12      U13      M10     M11      M12      M13  pre14expr\n",
      "0          128UP  2R   7924810   7926357     mat   103.24   89.70    95.07    83.99    97.29   76.26    94.38    64.46     704.39\n",
      "1  14-3-3EPSILON  3R  14068252  14074388     mat  1063.28  957.38  1300.41  1385.28  1257.24  861.66  1230.91  1399.05    9455.21\n",
      "2     14-3-3ZETA  2R   5987192   5995979     mat   484.54  377.29   610.11   604.96   550.95  312.00   581.16   589.49    4110.50\n",
      "3          140UP  3R   9949939   9951252  matzyg    15.74    7.80     7.64     2.52    12.81    4.14     6.43     4.26      61.34\n",
      "4            18W  2R  15999015  16004437     zyg     0.00    0.00     0.03     1.72     0.00    0.00     0.08     0.10       1.93\n",
      "========\n",
      "            NAME CHR       BEG       END   CLASS     F14A     U14A    F14B  F14B_r2     F14C  F14C_r2     F14D      M10     M11      M12      M13  stg14expr\n",
      "0          128UP  2R   7924810   7926357     mat    49.51    39.00   44.88    42.42    36.30    27.40    35.64    97.29   76.26    94.38    64.46     607.54\n",
      "1  14-3-3EPSILON  3R  14068252  14074388     mat  1123.37  1264.96  993.54  1608.84  1552.76  1591.29  1625.30  1257.24  861.66  1230.91  1399.05   14508.92\n",
      "2     14-3-3ZETA  2R   5987192   5995979     mat   507.27   440.57  359.13   488.56   382.55   414.34   396.89   550.95  312.00   581.16   589.49    5022.91\n",
      "3          140UP  3R   9949939   9951252  matzyg     0.82     0.98    1.18     1.21     7.06     5.74     9.97    12.81    4.14     6.43     4.26      54.60\n",
      "4            18W  2R  15999015  16004437     zyg     1.87     3.54    9.38    31.03    43.73    37.72    45.03     0.00    0.00     0.08     0.10     172.48\n",
      "(7775, 78)\n",
      "(12353, 80)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barricklab/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       matrix  motif_end  motif_start CHR   END  START  SUMMIT  pval  pval_cutoff  score  score_cutoff strand     TF   NAME       BEG CLASS  F:M SLOPE    F10    F11    F12    U13   F14A   U14A  F14B  F14B_r2  F14C  F14C_r2  F14D  U14D    M10    M11    M12    M13   M14A  M14A_r2  M14B  M14B_r2  M14C  M14C_r2  M14D  M14D_r2  w1_F10  w1_F11  w1_F12  w1_U13  w1_F14A  w1_U14A  w1_F14B  w1_F14B_r2  w1_F14C  w1_F14C_r2  w1_F14D  w1_U14D  w1_M10  w1_M11  w1_M12  w1_M13  w1_M14A  w1_M14A_r2  w1_M14B  w1_M14B_r2  w1_M14C  w1_M14C_r2  w1_M14D  w1_M14D_r2  cas_F10  cas_F11  cas_F12  cas_U13  cas_F14A  cas_U14A  cas_F14B  cas_F14B_r2  cas_F14C  cas_F14C_r2  cas_F14D  cas_U14D  cas_M10  cas_M11  cas_M12  cas_M13  cas_M14A  cas_M14A_r2  cas_M14B  cas_M14B_r2  cas_M14C  cas_M14C_r2  cas_M14D  cas_M14D_r2  pre14expr  stg14expr\n",
      "0  GATAd_SANGER_5_FBgn0032223         25           17  2L  6062   5699    5892 -7.95       -8.046   5.94           0.0      -  GATAD  GATAD  10333913   mat   0.972062  66.39  38.55  90.72  54.23  23.73  12.96  5.99     15.6  3.38     9.15   4.5  4.32  76.78  33.25  61.57  75.51  26.05    17.98  3.68    19.79  3.23     7.93  3.08      2.5     NaN     NaN     NaN     NaN      NaN      NaN      NaN         NaN      NaN         NaN      NaN      NaN     NaN     NaN     NaN     NaN      NaN         NaN      NaN         NaN      NaN         NaN      NaN         NaN      NaN      NaN      NaN      NaN       NaN       NaN       NaN          NaN       NaN          NaN       NaN       NaN      NaN      NaN      NaN      NaN       NaN          NaN       NaN          NaN       NaN          NaN       NaN          NaN      497.0     322.42\n",
      "1  GATAd_SANGER_5_FBgn0032223         46           38  2L  6062   5699    5892 -6.61       -8.046   4.32           0.0      +  GATAD  GATAD  10333913   mat   0.972062  66.39  38.55  90.72  54.23  23.73  12.96  5.99     15.6  3.38     9.15   4.5  4.32  76.78  33.25  61.57  75.51  26.05    17.98  3.68    19.79  3.23     7.93  3.08      2.5     NaN     NaN     NaN     NaN      NaN      NaN      NaN         NaN      NaN         NaN      NaN      NaN     NaN     NaN     NaN     NaN      NaN         NaN      NaN         NaN      NaN         NaN      NaN         NaN      NaN      NaN      NaN      NaN       NaN       NaN       NaN          NaN       NaN          NaN       NaN       NaN      NaN      NaN      NaN      NaN       NaN          NaN       NaN          NaN       NaN          NaN       NaN          NaN      497.0     322.42\n",
      "2  GATAd_SANGER_5_FBgn0032223        101           93  2L  6062   5699    5892 -4.82       -8.046   0.68           0.0      -  GATAD  GATAD  10333913   mat   0.972062  66.39  38.55  90.72  54.23  23.73  12.96  5.99     15.6  3.38     9.15   4.5  4.32  76.78  33.25  61.57  75.51  26.05    17.98  3.68    19.79  3.23     7.93  3.08      2.5     NaN     NaN     NaN     NaN      NaN      NaN      NaN         NaN      NaN         NaN      NaN      NaN     NaN     NaN     NaN     NaN      NaN         NaN      NaN         NaN      NaN         NaN      NaN         NaN      NaN      NaN      NaN      NaN       NaN       NaN       NaN          NaN       NaN          NaN       NaN       NaN      NaN      NaN      NaN      NaN       NaN          NaN       NaN          NaN       NaN          NaN       NaN          NaN      497.0     322.42\n",
      "3  GATAd_SANGER_5_FBgn0032223        144          136  2L  6062   5699    5892 -5.05       -8.046   1.41           0.0      +  GATAD  GATAD  10333913   mat   0.972062  66.39  38.55  90.72  54.23  23.73  12.96  5.99     15.6  3.38     9.15   4.5  4.32  76.78  33.25  61.57  75.51  26.05    17.98  3.68    19.79  3.23     7.93  3.08      2.5     NaN     NaN     NaN     NaN      NaN      NaN      NaN         NaN      NaN         NaN      NaN      NaN     NaN     NaN     NaN     NaN      NaN         NaN      NaN         NaN      NaN         NaN      NaN         NaN      NaN      NaN      NaN      NaN       NaN       NaN       NaN          NaN       NaN          NaN       NaN       NaN      NaN      NaN      NaN      NaN       NaN          NaN       NaN          NaN       NaN          NaN       NaN          NaN      497.0     322.42\n",
      "4  GATAd_SANGER_5_FBgn0032223        147          139  2L  6062   5699    5892 -4.61       -8.046   0.18           0.0      +  GATAD  GATAD  10333913   mat   0.972062  66.39  38.55  90.72  54.23  23.73  12.96  5.99     15.6  3.38     9.15   4.5  4.32  76.78  33.25  61.57  75.51  26.05    17.98  3.68    19.79  3.23     7.93  3.08      2.5     NaN     NaN     NaN     NaN      NaN      NaN      NaN         NaN      NaN         NaN      NaN      NaN     NaN     NaN     NaN     NaN      NaN         NaN      NaN         NaN      NaN         NaN      NaN         NaN      NaN      NaN      NaN      NaN       NaN       NaN       NaN          NaN       NaN          NaN       NaN       NaN      NaN      NaN      NaN      NaN       NaN          NaN       NaN          NaN       NaN          NaN       NaN          NaN      497.0     322.42\n",
      "['AC', 'ACHI', 'ADF1', 'AEF1', 'AMOS', 'AOP', 'AP', 'ATF-2', 'ATF6', 'ATO', 'BAB1', 'BAP', 'BCD', 'BR', 'BTBVII', 'BTD', 'CAD', 'CATO', 'CG10267', 'CG10904', 'CG11071', 'CG11085', 'CG11504', 'CG11617', 'CG12029', 'CG12155', 'CG12236', 'CG12605', 'CG12768', 'CG13897', 'CG14962', 'CG15601', 'CG17181', 'CG3065', 'CG31782', 'CG32105', 'CG32532', 'CG32830', 'CG3407', 'CG3838', 'CG3919', 'CG4360', 'CG4404', 'CG4854', 'CG5180', 'CG5669', 'CG5953', 'CG6276', 'CG7745', 'CG7928', 'CG8319', 'CG8765', 'CG9437', 'CIC', 'CRC', 'CREBA', 'CROL', 'CRP', 'CT', 'CWO', 'D19A', 'D19B', 'DA', 'DEAF1', 'DIP3', 'DL', 'DM', 'DREF', 'DYS', 'ECR', 'EIP74EF', 'EIP75B', 'EIP78C', 'ESG', 'ETS96B', 'ETS97D', 'EXD', 'EY', 'FER2', 'FOXO', 'FTZ-F1', 'GATAD', 'GCE', 'GL', 'GSB-N', 'H', 'HB', 'HER', 'HEY', 'HLH106', 'HLH4C', 'HLHM3', 'HLHMGAMMA', 'HNF4', 'HR39', 'HR46', 'HR78', 'HSF', 'JIGR1', 'JIM', 'KAY', 'KEN', 'L(1)SC', 'LAG1', 'LBE', 'LBL', 'LIM3', 'LOLA', 'MAD', 'MED', 'MES2', 'MET', 'MIO', 'MITF', 'NFAT', 'ODSH', 'OVO', 'PAD', 'PFK', 'PHO', 'PHOL', 'PNT', 'POXN', 'REL', 'RETN', 'RN', 'SC', 'SD', 'SLBO', 'SOX15', 'SQZ', 'SUG', 'SVP', 'TAI', 'TGO', 'TJ', 'TRL', 'TTK', 'UNPG', 'USF', 'USP', 'VFL', 'VIS', 'WOR', 'XRP1', 'Z', 'ZEN2']\n",
      "147\n",
      "356\n"
     ]
    }
   ],
   "source": [
    "lott2011_df = pd.read_csv(\"/Users/barricklab/Dropbox/Documents/Manuscripts/slicing/analysis_notebook/data/enhancers/Lott2011_DataS1.TXT\",sep=\"\\t\")\n",
    "print lott2011_df['NAME'].head()\n",
    "lott2011_df['NAME'] = [str(x).upper() for x in lott2011_df['NAME']]\n",
    "lott2011_df[\"pre14expr\"] = lott2011_df[[\"F10\",\"F11\",\"F12\",\"U13\",\"M10\",\"M11\",\"M12\",\"M13\"]].sum(axis=1)\n",
    "lott2011_df[\"stg14expr\"] = lott2011_df[[\"F14A\",\"U14A\",\"F14B\",\"F14B_r2\",\"F14C\",\"F14C_r2\",\"F14D\",\"M10\",\"M11\",\"M12\",\"M13\"]].sum(axis=1)\n",
    "\n",
    "print lott2011_df[[\"NAME\",\"CHR\",\"BEG\",\"END\",\"CLASS\",\"F10\",\"F11\",\"F12\",\"U13\",\"M10\",\"M11\",\"M12\",\"M13\",\"pre14expr\"]].head().to_string()\n",
    "print \"========\"\n",
    "print lott2011_df[[\"NAME\",\"CHR\",\"BEG\",\"END\",\"CLASS\",\"F14A\",\"U14A\",\"F14B\",\"F14B_r2\",\"F14C\",\"F14C_r2\",\"F14D\",\"M10\",\"M11\",\"M12\",\"M13\",\"stg14expr\"]].head().to_string()\n",
    "\n",
    "lott2011_early = lott2011_df[lott2011_df['pre14expr'] > (0.5 * lott2011_df['stg14expr'])]\n",
    "lott2011_early.drop(['CHR','END'],axis=1,inplace=True)\n",
    "print lott2011_early.shape\n",
    "print lott2011_df.shape\n",
    "gtAll_B1HTF_sites_lott2011flt = gtAll_B1HTF_sites.merge(lott2011_early, left_on='TF', right_on='NAME')\n",
    "print gtAll_B1HTF_sites_lott2011flt.head().to_string()\n",
    "\n",
    "print sorted(set(gtAll_B1HTF_sites_lott2011flt['TF']))\n",
    "print len(set(gtAll_B1HTF_sites_lott2011flt['TF']))\n",
    "print len(set(gtAll_B1HTF_sites['TF']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gtAll_B1HTF_sites_flt = gtAll_B1HTF_sites_lott2011flt[gtAll_B1HTF_sites_lott2011flt['pval'] < gtAll_B1HTF_sites_lott2011flt['pval_cutoff']]\n",
    "\n",
    "gtAllmrg_B1HTF_sites = pd.merge(gtAll_B1HTF_sites_lott2011flt, gtALL_highbind_pks, on=['CHR','START','END','SUMMIT'], how='right')\n",
    "gtA_B1HTF_sites = pd.merge(gtAll_B1HTF_sites, gtA_APfdr1_pks, on=['CHR','START','END','SUMMIT'], how='right')\n",
    "gtP_B1HTF_sites = pd.merge(gtAll_B1HTF_sites, gtP_APfdr1_pks, on=['CHR','START','END','SUMMIT'], how='right')\n",
    "gtND_B1HTF_sites = pd.merge(gtAll_B1HTF_sites, gtNoBias_highbind_pks, on=['CHR','START','END','SUMMIT'], how='right')\n",
    "gtBias_B1HF_sites = pd.merge(gtAll_B1HTF_sites, gtBias_APfdr1_pks, on=['CHR','START','END','SUMMIT'], how='right')\n",
    "\n",
    "gtAllmrg_B1HTF_sites_flt = pd.merge(gtAll_B1HTF_sites_flt, gtALL_highbind_pks, on=['CHR','START','END','SUMMIT'], how='right')\n",
    "gtA_B1HTF_sites_flt = pd.merge(gtAll_B1HTF_sites_flt, gtA_APfdr1_pks, on=['CHR','START','END','SUMMIT'], how='right')\n",
    "gtP_B1HTF_sites_flt = pd.merge(gtAll_B1HTF_sites_flt, gtP_APfdr1_pks, on=['CHR','START','END','SUMMIT'], how='right')\n",
    "gtND_B1HTF_sites_flt = pd.merge(gtAll_B1HTF_sites_flt, gtNoBias_highbind_pks, on=['CHR','START','END','SUMMIT'], how='right')\n",
    "gtBias_B1HTF_sites_flt = pd.merge(gtAll_B1HTF_sites_flt, gtBias_APfdr1_pks, on=['CHR','START','END','SUMMIT'], how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gtAll_B1HTF_sites_flt.to_csv(data_out_dir + \"motifs/gtAll_B1HTF_sites_Lott_early_TF.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
